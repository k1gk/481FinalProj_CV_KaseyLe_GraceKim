{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f1bdb4-1b3f-4add-8a26-008190c8cb45",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20454dfa-74b9-47e2-848c-04826cd8c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "import ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acbf491-1f63-4a0d-879a-d66672b8782a",
   "metadata": {},
   "source": [
    "Creating Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e3c3a-ad05-4445-939d-e1dffce3e2ae",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "1. WikiArt Art Movements/Styles(\"https://www.kaggle.com/datasets/sivarazadi/wikiart-art-movementsstyles?resource=download-directory&select=Romanticism\")\n",
    "   - Baroque: 1000 files\n",
    "   - Expressionism: 940 original files\n",
    "   - Realism: 1000 files\n",
    "   - Renaissance: 1000 files\n",
    "   - Romanticism: 1000 files\n",
    "2. Manual Data Collection: we created a new class called 'Cubism' and provided more files for Expressionism as it \n",
    "   - Cubism: 1000 files\n",
    "   - Expressionism: 1000 files (additional 60 files)\n",
    "3. Prediction Images\n",
    "   - We used the 3 unused images from dataset per class for prediction section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb73765-622b-43ac-8300-a115f6119b64",
   "metadata": {},
   "source": [
    "Folder Organization\n",
    "- Train: 80% of dataset\n",
    "- Val: 20% of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4f63be-6aa2-4055-89c1-971ac156fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\n",
    "    '../Downloads/RefinedArtStyles/train',\n",
    "    '../Downloads/RefinedArtStyles/val',\n",
    "    \n",
    "    '../Downloads/RefinedArtStyles/train/Baroque',\n",
    "    '../Downloads/RefinedArtStyles/train/Cubism',\n",
    "    '../Downloads/RefinedArtStyles/train/Expressionism',\n",
    "    '../Downloads/RefinedArtStyles/train/Realism',\n",
    "    '../Downloads/RefinedArtStyles/train/Renaissance',\n",
    "    '../Downloads/RefinedArtStyles/train/Romanticism',\n",
    "\n",
    "    '../Downloads/RefinedArtStyles/val/Baroque',\n",
    "    '../Downloads/RefinedArtStyles/val/Cubism',\n",
    "    '../Downloads/RefinedArtStyles/val/Expressionism',\n",
    "    '../Downloads/RefinedArtStyles/val/Realism',\n",
    "    '../Downloads/RefinedArtStyles/val/Renaissance',\n",
    "    '../Downloads/RefinedArtStyles/val/Romanticism'    \n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b07065-485c-4c25-8cef-48057bc08a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "baroque_source = '../Downloads/RefinedArtStyles/Baroque'\n",
    "baroque_train = '../Downloads/RefinedArtStyles/train/Baroque'\n",
    "baroque_val = '../Downloads/RefinedArtStyles/val/Baroque'\n",
    "\n",
    "expression_source = '../Downloads/RefinedArtStyles/Expressionism'\n",
    "expression_train = '../Downloads/RefinedArtStyles/train/Expressionism'\n",
    "expression_val = '../Downloads/RefinedArtStyles/val/Expressionism'\n",
    "\n",
    "realism_source = '../Downloads/RefinedArtStyles/Realism'\n",
    "realism_train = '../Downloads/RefinedArtStyles/train/Realism'\n",
    "realism_val = '../Downloads/RefinedArtStyles/val/Realism'\n",
    "\n",
    "renaissance_source = '../Downloads/RefinedArtStyles/Renaissance'\n",
    "renaissance_train = '../Downloads/RefinedArtStyles/train/Renaissance'\n",
    "renaissance_val = '../Downloads/RefinedArtStyles/val/Renaissance'\n",
    "\n",
    "romanticism_source = '../Downloads/RefinedArtStyles/Romanticism'\n",
    "romanticism_train = '../Downloads/RefinedArtStyles/train/Romanticism'\n",
    "romanticism_val = '../Downloads/RefinedArtStyles/val/Romanticism'\n",
    "\n",
    "cubism_source = '../Downloads/RefinedArtStyles/Cubism'\n",
    "cubism_train = '../Downloads/RefinedArtStyles/train/Cubism'\n",
    "cubism_val = '../Downloads/RefinedArtStyles/val/Cubism'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9defe6-ef9b-46f9-9ab6-5ba7b99d570e",
   "metadata": {},
   "source": [
    "Dataset Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76bba056-b08d-4b7b-8b8e-311466abb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def organize_file(source_dir, train_dir, val_dir):\n",
    "    files = []\n",
    "    for f in os.listdir(source_dir):\n",
    "        files.append(f)\n",
    "\n",
    "    if len(files) == 0:\n",
    "        print(\"No files found in the source directory:\", source_dir)\n",
    "        return\n",
    "    \n",
    "    train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for file in train_files:\n",
    "        file_path = os.path.join(source_dir, file)\n",
    "        image = Image.open(file_path).convert(\"RGB\")\n",
    "        image.save(os.path.join(train_dir, file), \"JPEG\") \n",
    "        \n",
    "    for file in val_files:\n",
    "        file_path = os.path.join(source_dir, file)\n",
    "        image = Image.open(file_path).convert(\"RGB\")\n",
    "        image.save(os.path.join(val_dir, file), \"JPEG\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d590888b-4cf0-4577-a667-da6b81d78aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_file(baroque_source, baroque_train, baroque_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4fc41ea-5f65-44ef-8aa2-52bb6b92840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_file(expression_source, expression_train, expression_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ff87d5-3b24-4590-bfa0-e78edc32074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_file(realism_source, realism_train, realism_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50ffd6e4-e07a-4939-841a-38214020f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_file(renaissance_source, renaissance_train, renaissance_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f995f911-a3f8-4bf4-b84c-b5df3288339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_file(romanticism_source, romanticism_train, romanticism_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a676f490-88cb-4394-8bc2-bdc45f8225fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_file(cubism_source, cubism_train, cubism_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373f821-1048-4965-9ae3-1407605ba842",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "053c7251-5293-4af8-a8b2-07c633c783df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=RefinedArtStyles, epochs=3, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train4\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    337926  ultralytics.nn.modules.head.Classify         [256, 6]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1445974 parameters, 1445974 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train4', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... 4800 images, 0 corrupt: 100%|██████████| 4800/4800 [\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... 1200 images, 0 corrupt: 100%|██████████| 1200/1200 [00:0\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train4\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.364         16        224: 100%|██████████| 300/300 [03:26<00:00,  1.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.668      0.997\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3         0G     0.8824         16        224: 100%|██████████| 300/300 [03:22<00:00,  1.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:35<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.753      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G     0.7443         16        224: 100%|██████████| 300/300 [03:16<00:00,  1.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:34<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.802      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.198 hours.\n",
      "Optimizer stripped from runs\\classify\\train4\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from runs\\classify\\train4\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating runs\\classify\\train4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1442566 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:33<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.804      0.999\n",
      "Speed: 0.0ms preprocess, 3.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train4\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\train4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022C67E785D0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.901666671037674\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8041666746139526, 'metrics/accuracy_top5': 0.9991666674613953, 'fitness': 0.901666671037674}\n",
       "save_dir: WindowsPath('runs/classify/train4')\n",
       "speed: {'preprocess': 0.000831286112467448, 'inference': 3.923502763112386, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.8041666746139526\n",
       "top5: 0.9991666674613953"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = YOLO('yolov8n-cls.pt')\n",
    "model1.train(data='RefinedArtStyles', epochs=3, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d365722-0731-4169-98bb-95c6278e4e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=RefinedArtStyles, epochs=5, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train5\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    337926  ultralytics.nn.modules.head.Classify         [256, 6]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1445974 parameters, 1445974 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train5', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... 4800 images, 0 corrupt: 100%|██████████| 4800/4800 [\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... 1200 images, 0 corrupt: 100%|██████████| 1200/1200 [00:0\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train5\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G      1.364         16        224: 100%|██████████| 300/300 [03:23<00:00,  1.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.668      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         0G     0.8802         16        224: 100%|██████████| 300/300 [03:19<00:00,  1.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:33<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.746      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/5         0G     0.7469         16        224: 100%|██████████| 300/300 [03:52<00:00,  1.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:36<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.8      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        4/5         0G     0.6402         16        224: 100%|██████████| 300/300 [03:15<00:00,  1.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:35<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.827          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        5/5         0G     0.5607         16        224: 100%|██████████| 300/300 [03:13<00:00,  1.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:35<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.836          1\n",
      "\n",
      "5 epochs completed in 0.334 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs\\classify\\train5\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from runs\\classify\\train5\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating runs\\classify\\train5\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1442566 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 38/38 [00:33<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.836          1\n",
      "Speed: 0.0ms preprocess, 3.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train5\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\train5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022C6A34C1D0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9179166555404663\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8358333110809326, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9179166555404663}\n",
       "save_dir: WindowsPath('runs/classify/train5')\n",
       "speed: {'preprocess': 0.0024878978729248047, 'inference': 3.761421243349711, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.8358333110809326\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = YOLO('yolov8n-cls.pt')\n",
    "model2.train(data='RefinedArtStyles', epochs=5, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f818b2e4-fe30-4e6b-b669-c993b4e2fc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=RefinedArtStyles, epochs=3, time=None, patience=100, batch=20, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train6\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    337926  ultralytics.nn.modules.head.Classify         [256, 6]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1445974 parameters, 1445974 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train6', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... 4800 images, 0 corrupt: 100%|██████████| 4800/4800 [\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... 1200 images, 0 corrupt: 100%|██████████| 1200/1200 [00:0\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.00046875), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train6\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.371         20        224: 100%|██████████| 240/240 [03:07<00:00,  1.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:33<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.673      0.996\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3         0G     0.8742         20        224: 100%|██████████| 240/240 [03:07<00:00,  1.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:33<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.752      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G     0.7254         20        224: 100%|██████████| 240/240 [02:26<00:00,  1.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:24<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.8          1\n",
      "\n",
      "3 epochs completed in 0.171 hours.\n",
      "Optimizer stripped from runs\\classify\\train6\\weights\\last.pt, 3.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs\\classify\\train6\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating runs\\classify\\train6\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1442566 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.8          1\n",
      "Speed: 0.0ms preprocess, 3.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train6\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\train6\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022C684FC1D0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9000000059604645\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.800000011920929, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9000000059604645}\n",
       "save_dir: WindowsPath('runs/classify/train6')\n",
       "speed: {'preprocess': 0.0016609827677408855, 'inference': 3.3077943325042725, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.800000011920929\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = YOLO('yolov8n-cls.pt')\n",
    "model3.train(data='RefinedArtStyles', epochs=3, batch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d17d91a0-a4ab-45c0-ae1f-b1cdf84b4851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=RefinedArtStyles, epochs=5, time=None, patience=100, batch=20, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train7\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    337926  ultralytics.nn.modules.head.Classify         [256, 6]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1445974 parameters, 1445974 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train7', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... 4800 images, 0 corrupt: 100%|██████████| 4800/4800 [\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... 1200 images, 0 corrupt: 100%|██████████| 1200/1200 [00:0\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.00046875), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train7\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G      1.371         20        224: 100%|██████████| 240/240 [02:22<00:00,  1.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:24<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.673      0.996\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/5         0G     0.8712         20        224: 100%|██████████| 240/240 [02:19<00:00,  1.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:24<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.749      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/5         0G     0.7242         20        224: 100%|██████████| 240/240 [02:18<00:00,  1.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:24<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.793          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        4/5         0G     0.6115         20        224: 100%|██████████| 240/240 [02:20<00:00,  1.71it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:24<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.824          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        5/5         0G     0.5375         20        224: 100%|██████████| 240/240 [02:20<00:00,  1.71it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:23<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.839      0.999\n",
      "\n",
      "5 epochs completed in 0.229 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs\\classify\\train7\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from runs\\classify\\train7\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating runs\\classify\\train7\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1442566 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 30/30 [00:23<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.838      0.999\n",
      "Speed: 0.0ms preprocess, 3.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train7\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\train7\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022C03830410>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.918749988079071\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8383333086967468, 'metrics/accuracy_top5': 0.9991666674613953, 'fitness': 0.918749988079071}\n",
       "save_dir: WindowsPath('runs/classify/train7')\n",
       "speed: {'preprocess': 0.0008285045623779297, 'inference': 3.1949156522750854, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.8383333086967468\n",
       "top5: 0.9991666674613953"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = YOLO('yolov8n-cls.pt')\n",
    "model4.train(data='RefinedArtStyles', epochs=5, batch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8658095-81fb-4fb8-94b8-2da00a821178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=RefinedArtStyles, epochs=5, time=None, patience=100, batch=12, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train8\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    337926  ultralytics.nn.modules.head.Classify         [256, 6]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1445974 parameters, 1445974 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train8', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... 4800 images, 0 corrupt: 100%|██████████| 4800/4800 [\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... 1200 images, 0 corrupt: 100%|██████████| 1200/1200 [00:0\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.00046875), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train8\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G      1.362         12        224: 100%|██████████| 400/400 [02:23<00:00,  2.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 50/50 [00:24<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.676      0.996\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/5         0G     0.8968         12        224: 100%|██████████| 400/400 [02:20<00:00,  2.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 50/50 [00:24<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.754      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/5         0G     0.7815         12        224: 100%|██████████| 400/400 [02:22<00:00,  2.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 50/50 [00:23<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.799      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        4/5         0G     0.6877         12        224: 100%|██████████| 400/400 [02:18<00:00,  2.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 50/50 [00:24<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        5/5         0G      0.596         12        224: 100%|██████████| 400/400 [02:20<00:00,  2.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 50/50 [00:24<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.832          1\n",
      "\n",
      "5 epochs completed in 0.230 hours.\n",
      "Optimizer stripped from runs\\classify\\train8\\weights\\last.pt, 3.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs\\classify\\train8\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating runs\\classify\\train8\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1442566 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 50/50 [00:23<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.833          1\n",
      "Speed: 0.0ms preprocess, 3.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train8\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\train8\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022C0337CD10>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9166666567325592\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8333333134651184, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9166666567325592}\n",
       "save_dir: WindowsPath('runs/classify/train8')\n",
       "speed: {'preprocess': 0.0, 'inference': 3.215980728467305, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.8333333134651184\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = YOLO('yolov8n-cls.pt')\n",
    "model5.train(data='RefinedArtStyles', epochs=5, batch=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a51dca-f62d-4f16-ae56-a7da7b9bf12c",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f00ebdb4-c800-4709-ac49-7ccc7dbf262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47  Python-3.11.7 torch-2.2.2+cpu CPU (11th Gen Intel Core(TM) i9-11900K 3.50GHz)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1442566 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\train... found 4800 images in 6 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... found 1200 images in 6 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kwkim\\Downloads\\RefinedArtStyles\\val... 1200 images, 0 corrupt: 100%|██████████| 1200/1200 [00:0\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:23<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.838      0.999\n",
      "Speed: 0.0ms preprocess, 3.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\val2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9991666674613953"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = \"Downloads/RefinedArtStyles/val\"\n",
    "\n",
    "#below model 1 is a placeholder: change the model name and the folder to use the better model among model1 and model 2\n",
    "model4 = YOLO(\"runs/classify/train7/weights/best.pt\")\n",
    "\n",
    "metrics4 = model4.val()\n",
    "metrics4.top1\n",
    "metrics4.top5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a7fa9-7fe8-4286-9a86-5367dc4d8bd8",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c3b10f5-daba-4238-b438-cdf20c4a66be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Baroque(5310).jpg: 224x224 Romanticism 0.57, Renaissance 0.30, Expressionism 0.05, Baroque 0.04, Realism 0.03, 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Baroque(5311).jpg: 224x224 Romanticism 0.67, Baroque 0.14, Renaissance 0.12, Realism 0.04, Expressionism 0.03, 10.0ms\n",
      "Speed: 18.9ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Baroque(5312).jpg: 224x224 Baroque 0.64, Renaissance 0.32, Romanticism 0.03, Realism 0.01, Expressionism 0.00, 7.0ms\n",
      "Speed: 16.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Cubism(1081).jpg: 224x224 Cubism 0.90, Renaissance 0.05, Expressionism 0.03, Baroque 0.01, Realism 0.01, 7.0ms\n",
      "Speed: 14.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Cubism(1109).jpg: 224x224 Cubism 1.00, Expressionism 0.00, Renaissance 0.00, Baroque 0.00, Romanticism 0.00, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Cubism(1110).jpg: 224x224 Cubism 0.98, Expressionism 0.02, Renaissance 0.00, Baroque 0.00, Realism 0.00, 7.0ms\n",
      "Speed: 4.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Expressionism(4311).jpg: 224x224 Expressionism 0.63, Realism 0.33, Cubism 0.03, Romanticism 0.01, Renaissance 0.00, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Expressionism(4350).jpg: 224x224 Cubism 0.51, Expressionism 0.34, Realism 0.06, Romanticism 0.05, Renaissance 0.04, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Expressionism(4358).jpg: 224x224 Renaissance 0.35, Romanticism 0.26, Expressionism 0.20, Realism 0.11, Cubism 0.07, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Realism(5357).jpg: 224x224 Romanticism 0.86, Realism 0.11, Expressionism 0.02, Baroque 0.01, Renaissance 0.00, 7.0ms\n",
      "Speed: 26.9ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Realism(5365).jpg: 224x224 Realism 0.30, Romanticism 0.26, Baroque 0.24, Renaissance 0.16, Expressionism 0.05, 10.0ms\n",
      "Speed: 9.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Realism(5373).jpg: 224x224 Romanticism 0.71, Renaissance 0.10, Realism 0.08, Expressionism 0.07, Baroque 0.03, 8.0ms\n",
      "Speed: 15.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Renaissance(6190).jpg: 224x224 Baroque 0.60, Renaissance 0.23, Realism 0.11, Romanticism 0.06, Cubism 0.00, 8.0ms\n",
      "Speed: 4.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Renaissance(6191).jpg: 224x224 Baroque 0.55, Renaissance 0.41, Romanticism 0.02, Realism 0.02, Expressionism 0.00, 10.0ms\n",
      "Speed: 4.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Renaissance(6192).jpg: 224x224 Renaissance 0.96, Baroque 0.02, Realism 0.01, Romanticism 0.00, Expressionism 0.00, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Romanticism(6811).jpg: 224x224 Romanticism 0.47, Realism 0.32, Baroque 0.18, Expressionism 0.02, Renaissance 0.01, 8.0ms\n",
      "Speed: 8.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Romanticism(6812).jpg: 224x224 Romanticism 0.92, Expressionism 0.06, Baroque 0.01, Realism 0.01, Renaissance 0.00, 10.0ms\n",
      "Speed: 34.9ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "\n",
      "image 1/1 C:\\Users\\kwkim\\Downloads\\..\\Downloads\\predict_img\\Romanticism(6811).jpg: 224x224 Romanticism 0.47, Realism 0.32, Baroque 0.18, Expressionism 0.02, Renaissance 0.01, 8.0ms\n",
      "Speed: 7.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "ultralytics.engine.results.Probs object with attributes:\n",
      "\n",
      "data: tensor([1.7657e-01, 1.4241e-04, 2.2659e-02, 3.1859e-01, 1.2873e-02, 4.6917e-01])\n",
      "orig_shape: None\n",
      "shape: torch.Size([6])\n",
      "top1: 5\n",
      "top1conf: tensor(0.4692)\n",
      "top5: [5, 3, 0, 2, 4]\n",
      "top5conf: tensor([0.4692, 0.3186, 0.1766, 0.0227, 0.0129]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#below model 1 is a placeholder: change the model name and the folder to use the better model among model1 and model 2\n",
    "model4 = YOLO(\"runs/classify/train7/weights/best.pt\")\n",
    "\n",
    "m4_results = model4('../Downloads/predict_img/Baroque(5310).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Baroque(5311).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Baroque(5312).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Cubism(1081).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Cubism(1109).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Cubism(1110).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Expressionism(4311).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Expressionism(4350).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Expressionism(4358).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Realism(5357).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Realism(5365).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Realism(5373).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Renaissance(6190).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Renaissance(6191).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Renaissance(6192).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Romanticism(6811).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Romanticism(6812).jpg', save=True)\n",
    "m4_results = model4('../Downloads/predict_img/Romanticism(6811).jpg', save=True)\n",
    "\n",
    "for r in m4_results:\n",
    "    print(r.probs, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
